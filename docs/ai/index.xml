<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI相关 on 技术的路上奔跑</title>
    <link>/docs/ai/</link>
    <description>Recent content in AI相关 on 技术的路上奔跑</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="/docs/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>名词解释和学习大纲</title>
      <link>/docs/ai/keywords/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ai/keywords/</guid>
      <description>一、人工智能通识 # 1. 数学基础 # 1.1. 归一化 # 对数据范围缩小到(0, 1)范围内 为什么做归一化 # 会对准确率造成影响。不对数据进行归一化的话，如果你的网络层数又比较多的话，很有可能会造成梯度消失或梯度爆炸，而这会对你的权重的更新会造成很大的影响进而会影响模型的性能。 另外，如果你的特征之间因为量纲的影响而造成数据之间的数量级差别很大的话也会对训练出的模型的性能造成影响
1.2. 梯度消失和梯度爆炸 # 梯度消失: 在反向传播过程中，随着算法向下传播到较低层，梯度通常会越来越小。结果梯度下降更新使较低层的连接权重保持不变，训练不能收敛到一个好的最优解 梯度爆炸: 在某些情况下，可能会出现相反的情况：梯度可能会越来越大，各层需要更新很大的权重直到算法发散为止 1.3. 精确度、准确率、召回率 # TP (True Positives): 真实的为1的样本（样本为true，预测准确，预测为true） TN (True Negatives): 真实的为0的样本（样本为false，预测准确，预测为false） FP (False Positives): 错误预测为1的样本（样本为false，预测错误，预测为true） FN (False Negatives): 错误预测为0的样本（样本为true，预测错误，预测为false）
精确度 precision # $$ P = \frac{TP}{TP+FP} = \frac{实际为1被判定正确的数量}{预测为1的样本总数} $$
主要反映对于0的误判率，如恶意文件扫描，精确度反映了对于恶意文件的扫描精确程度 换成一杯水，代表水中真实可以喝的水占整体水的总量 为1代表预测的正样本都是对的 准确率 accuracy # $$ A = \frac{TP+TN}{TP+TN+FP+FN} = \frac{实际为1判定正确的数量+实际为0判定正确的数量}{样本总数} $$
准确率就是展示模型是否准确的基本数值 召回率 recall # $$ R = \frac{TP}{TP+FN} = \frac{实际为1被判定正确的数量}{实际为1的样本总数} $$</description>
    </item>
    
  </channel>
</rss>
